{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTANT NOTE:\n",
    "Streamlit before 0.57 only works with Bokeh 1.0 and Streamlit 0.57+ only works with Bokeh 2.<br>\n",
    "I have used **Streamlit 0.62.0** and **Bokeh 2.1.1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Streamlit and Bokeh\n",
    "#!pip install streamlit\n",
    "#!pip install bokeh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which version is in your computer\n",
    "!streamlit --version\n",
    "!bokeh info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !streamlit hello"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "## Explanation about functions used below:\n",
    "```python\n",
    "def get_LocationIDs():\n",
    "```\n",
    "Creates a DataFrame with the LocationID of Manhattan zones\n",
    "\n",
    "\n",
    "```python\n",
    "def datetimeInfo_and_LocID(df_LocIds, start_date, NoOfDays):\n",
    "```\n",
    "Creates a DataFrame with the Datetime info and LocationID and make the appropriate transforms to pass it on to the predictive model.\n",
    "It uses tomorrows day, up to 3 more days.\n",
    "\n",
    "\n",
    "```python\n",
    "def scrape_data(today, days_in):\n",
    "```\n",
    "Scrape Precipitation forecast from wunderground.com.\n",
    "From tomorrow up to 3 more days.\n",
    "\n",
    "\n",
    "```python\n",
    "def get_input_data(start_date, NoOfDays):\n",
    "```\n",
    "It takes the outputs from 'datetimeInfo_and_LocID' and 'scrape_data' and output another DataFrame, ready to be taken by the predictive model.\n",
    "\n",
    "\n",
    "```python\n",
    "def get_output_data(pickle_file, input_data):\n",
    "```\n",
    "It passes input_data on to the predictive model and outputs a result DataFrame with: dayofweek, hour, LocationID, NoOfPickups.\n",
    "\n",
    "\n",
    "```python\n",
    "def load_shape_data():\n",
    "```\n",
    "Creates a DataFrame with LocationIDs and their associated (X,Y) coordinates to so they can be plot as a map.\n",
    "\n",
    "\n",
    "```python\n",
    "def load_taxis_data(output_data, shape_data):\n",
    "```\n",
    "It takes outputs from 'get_output_data' and 'load_shape_data' and transforms the tables so that it can be plotted, associating slider values to different columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile streamlit_app.py\n",
    "\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date, timedelta\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon, MultiPolygon\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from bokeh.io import output_notebook, output_file, show\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.models import HoverTool, Select, ColumnDataSource, WheelZoomTool, LogColorMapper, LinearColorMapper, ColorBar, BasicTicker\n",
    "from bokeh.palettes import Viridis256 as palette\n",
    "from bokeh.layouts import row\n",
    "\n",
    "\n",
    "#############################   DEFINE FUNCTIONS START   #############################\n",
    "\n",
    "# GET LOCATION ID DATA FRAME\n",
    "# when deploying to external server, consider create LocationIDs manually instead of reading csv\n",
    "@st.cache\n",
    "def get_LocationIDs():\n",
    "    # 1. Import Location and Borough columns form NY TAXI ZONES dataset\n",
    "    dfzones = pd.read_csv('../data/NY_taxi_zones.csv', sep=',',\n",
    "                          usecols=['LocationID', 'borough'])\n",
    "\n",
    "    # 2. Filter Manhattan zones\n",
    "    dfzones = dfzones[dfzones['borough']=='Manhattan']\\\n",
    "                    .drop(['borough'], axis=1)\\\n",
    "                    .sort_values(by='LocationID')\\\n",
    "                    .drop_duplicates('LocationID').reset_index(drop=True)    \n",
    "    return dfzones\n",
    "\n",
    "# CREATE DATETIME INFO AND APPEND LOCATION IDs\n",
    "@st.cache\n",
    "def datetimeInfo_and_LocID(df_LocIds, start_date, NoOfDays):   \n",
    "\n",
    "    # repeat LocationIDs. All of them... for each hour\n",
    "    location_id_col = pd.concat([df_LocIds]*24*NoOfDays).reset_index(drop=True)\n",
    "\n",
    "    # create data frame with range of days with hourly period\n",
    "    df_pred = pd.DataFrame()\n",
    "    dates = pd.date_range(start = start_date, end = start_date + timedelta(days=NoOfDays), freq = \"H\")\n",
    "    df_pred['datetime'] = dates\n",
    "    df_pred.drop([df_pred.shape[0]-1], inplace=True)\n",
    "\n",
    "    # Create new columns from datetime\n",
    "    df_pred['month'] = df_pred['datetime'].dt.month\n",
    "    df_pred['day'] = df_pred['datetime'].dt.day\n",
    "    df_pred['hour'] = df_pred['datetime'].dt.hour\n",
    "    # 'dayhour' will serve as index to perform the join\n",
    "    df_pred['dayhour'] = df_pred['datetime'].dt.strftime('%d%H')\n",
    "    df_pred['week'] = df_pred['datetime'].dt.week\n",
    "    df_pred['dayofweek'] = df_pred['datetime'].dt.dayofweek\n",
    "        # create column 'isweekend'\n",
    "    mask = (df_pred['dayofweek'] == 5) | (df_pred['dayofweek'] == 6)\n",
    "    df_pred['isweekend'] = np.where(mask, 1, 0)\n",
    "\n",
    "    # drop datetime column\n",
    "    df_pred.drop(['datetime'], axis=1, inplace=True)\n",
    "\n",
    "    # repeat rows. 67 rows per hour\n",
    "    df_pred = df_pred.iloc[np.arange(len(df_pred)).repeat(len(df_LocIds))].reset_index(drop=True)\n",
    "    #df_index = df_index.iloc[np.arange(len(df_index)).repeat(67)].reset_index(drop=True)\n",
    "\n",
    "    df_pred = df_pred.join(location_id_col)\n",
    "    \n",
    "    return df_pred\n",
    "\n",
    "# SCRAPE PRECIPITATION FORECAST FROM wunderground.com\n",
    "@st.cache\n",
    "def scrape_data(today, days_in):\n",
    "    # Use .format(YYYY, M, D)\n",
    "    lookup_URL = 'https://www.wunderground.com/hourly/us/ny/new-york-city/date/{}-{}-{}.html'\n",
    "\n",
    "    options = webdriver.ChromeOptions();\n",
    "    options.add_argument('headless'); # to run chrome in the backbroung\n",
    "\n",
    "    driver = webdriver.Chrome(executable_path='./chromedriver.exe', options=options)\n",
    "\n",
    "    start_date = today + pd.Timedelta(days=1)\n",
    "    end_date = today + pd.Timedelta(days=days_in + 1)\n",
    "\n",
    "    df_prep = pd.DataFrame()\n",
    "\n",
    "    while start_date != end_date:\n",
    "        timestamp = pd.Timestamp(str(start_date)+' 00:00:00')\n",
    "        \n",
    "        print('gathering data from: ', start_date)\n",
    "        \n",
    "        formatted_lookup_URL = lookup_URL.format(start_date.year,\n",
    "                                                 start_date.month,\n",
    "                                                 start_date.day)\n",
    "\n",
    "        driver.get(formatted_lookup_URL)\n",
    "        rows = WebDriverWait(driver, 60).until(EC.visibility_of_all_elements_located((By.XPATH, '//td[@class=\"mat-cell cdk-cell cdk-column-liquidPrecipitation mat-column-liquidPrecipitation ng-star-inserted\"]')))\n",
    "        for row in rows:\n",
    "            hour = timestamp.strftime('%H')\n",
    "            day = timestamp.strftime('%d')\n",
    "            prep = row.find_element_by_xpath('.//span[@class=\"wu-value wu-value-to\"]').text\n",
    "            # append new row to table\n",
    "            # 'dayhour' column will serve as column index to perform the Join\n",
    "            df_prep = df_prep.append(pd.DataFrame({\"dayhour\":[day+hour], 'precipitation':[prep]}),\n",
    "                                     ignore_index = True)\n",
    "            \n",
    "            timestamp += pd.Timedelta('1 hour')\n",
    "\n",
    "        start_date += timedelta(days=1)\n",
    "    return df_prep\n",
    "\n",
    "# GET INPUT DATA USING THE FUNCTIONS ABOVE: LocationIDs and Datetime info\n",
    "@st.cache\n",
    "def get_input_data(start_date, NoOfDays):\n",
    "    # get LocationIDs data frame\n",
    "    df_LocIds = get_LocationIDs()\n",
    "\n",
    "    # create datetime info and append LocationsIDs\n",
    "    dtInfo_and_LocID = datetimeInfo_and_LocID(df_LocIds,start_date,NoOfDays)\n",
    "\n",
    "    # get precipitation forecast\n",
    "    prep_forecast = scrape_data(date.today(), NoOfDays)\n",
    "\n",
    "    # merge both data frames\n",
    "    df_merged = dtInfo_and_LocID.merge(prep_forecast, on=\"dayhour\", how=\"left\")\n",
    "\n",
    "    # drop dayhour column\n",
    "    df_merged = df_merged.drop(['dayhour'], axis=1)\n",
    "    \n",
    "    return df_merged\n",
    "\n",
    "# GET OUPPUT DATA: get predictions, append to input_data and format it to be processed\n",
    "@st.cache\n",
    "def get_output_data(pickle_file, input_data):\n",
    "    import pickle\n",
    "\n",
    "    model = pickle.load(open(pickle_file,'rb'))\n",
    "\n",
    "    # get prediction, convert to integer and convert Array into DataFrame\n",
    "    model_predict = (model.predict(input_data)).astype(int)\n",
    "    df_predict = pd.DataFrame({'NoOfPickups':model_predict})\n",
    "\n",
    "    # join input_data with DataFrame\n",
    "    joined = input_data.join(df_predict)\n",
    "    \n",
    "    output_data = joined[['hour','dayofweek','LocationID','NoOfPickups']]\n",
    "    \n",
    "    return output_data\n",
    "\n",
    "# GET DATA FRAME WITH SHAPE GEOMETRY INFO\n",
    "@st.cache\n",
    "def load_shape_data():\n",
    "    shape_data = gpd.read_file('../data/taxi_zones/taxi_zones.shp')\n",
    "\n",
    "    # filter Manhattan zones\n",
    "    shape_data = shape_data[shape_data['borough'] == 'Manhattan'].reset_index(drop=True)\n",
    "\n",
    "    shape_data = shape_data.drop(['borough'], axis=1)\n",
    "\n",
    "    shape_data.to_crs(epsg=3785, inplace=True)\n",
    "\n",
    "    #EPSG-Code of Web Mercador\n",
    "\n",
    "    # Simplify Shape of Zones (otherwise slow peformance of plot)\n",
    "    shape_data[\"geometry\"] = shape_data[\"geometry\"].simplify(100)\n",
    "\n",
    "    data = []\n",
    "    for zonename, LocationID, shape in shape_data[[\"zone\", \"LocationID\", \"geometry\"]].values:\n",
    "        #If shape is polygon, extract X and Y coordinates of boundary line:\n",
    "        if isinstance(shape, Polygon):\n",
    "            X, Y = shape.boundary.xy\n",
    "            X = [int(x) for x in X]\n",
    "            Y = [int(y) for y in Y]\n",
    "            data.append([LocationID, zonename, X, Y])\n",
    "\n",
    "        #If shape is Multipolygon, extract X and Y coordinates of each sub-Polygon:\n",
    "        if isinstance(shape, MultiPolygon):\n",
    "            for poly in shape:\n",
    "                X, Y = poly.boundary.xy\n",
    "                X = [int(x) for x in X]\n",
    "                Y = [int(y) for y in Y]\n",
    "                data.append([LocationID, zonename, X, Y])\n",
    "\n",
    "    #Create new DataFrame with X an Y coordinates separated:\n",
    "    shape_data = pd.DataFrame(data, columns=[\"LocationID\", \"ZoneName\", \"X\", \"Y\"])\n",
    "    return shape_data\n",
    "\n",
    "@st.cache(allow_output_mutation=True)\n",
    "def load_taxis_data(output_data, shape_data):\n",
    "    df_to_visualize = shape_data.copy()\n",
    "    pickups = output_data.groupby(['hour','dayofweek','LocationID']).sum()\n",
    "    start_day = pd.unique(output_data['dayofweek']).min()\n",
    "    end_day = pd.unique(output_data['dayofweek']).max()\n",
    "\n",
    "    for hour in range(24):\n",
    "        for dayofweek in range(start_day,end_day+1,1):\n",
    "            # get pickups for this hour and weekday\n",
    "            p = pd.DataFrame(pickups.loc[(hour, dayofweek)]).reset_index()\n",
    "        \n",
    "            # add pickups to the Taxi Zones DataFrame       \n",
    "            df_to_visualize = pd.merge(df_to_visualize, p, on=\"LocationID\", how=\"left\").fillna(0)\n",
    "            # rename column as per day and hour\n",
    "            df_to_visualize.rename(columns={\"NoOfPickups\" : \"Passenger_%d_%d\"%(dayofweek, hour)}, inplace=True)\n",
    "\n",
    "    return df_to_visualize\n",
    "\n",
    "\n",
    "#############################   DEFINE FUNCTIONS END   #############################\n",
    "\n",
    "# DECLARE VARIABLES: start date, NoOfDays, pickle_file\n",
    "start_date = date.today() + timedelta(days=1) # start day is tomorrow\n",
    "NoOfDays = 3 # number of days for prediction\n",
    "pickle_file = './model_reg_01.pickle'\n",
    "\n",
    "# RUN FUNCTIONS\n",
    "input_data = get_input_data(start_date, NoOfDays)\n",
    "\n",
    "output_data = get_output_data(pickle_file, input_data)\n",
    "\n",
    "shape_data = load_shape_data()\n",
    "\n",
    "df_to_visualize = load_taxis_data(output_data,shape_data)\n",
    "\n",
    "# SHOW TITLE AND DESCRIPTION\n",
    "st.title(\"Taxi Demand Predictor\")\n",
    "\"\"\"\n",
    "Write some description here\n",
    "\"\"\"\n",
    "\n",
    "# add slider widget: Hours\n",
    "hour = st.slider(\"Hour\",min_value=0, max_value=23, value=7, step=1)\n",
    "\n",
    "\n",
    "# add slider widget: Dayofweek\n",
    "weekday_start = pd.unique(output_data['dayofweek']).min()\n",
    "weekday_end = pd.unique(output_data['dayofweek']).max()\n",
    "weekday = st.slider(\"Day of week\",min_value=int(weekday_start), max_value=int(weekday_end), step=1)\n",
    "\n",
    "\n",
    "# ColumnDataSource transforms the data into something that Bokeh and Java understand\n",
    "df_to_visualize[\"Passengers\"] = df_to_visualize[\"Passenger_\" + str(weekday) + \"_\" + str(hour)]\n",
    "\n",
    "source = ColumnDataSource(df_to_visualize)\n",
    "\n",
    "max_passengers_per_hour = df_to_visualize[filter(lambda x: \"Passenger_\" in x, df_to_visualize.columns)].max().max()\n",
    "\n",
    "color_mapper = LinearColorMapper(palette=palette[::-1], high=max_passengers_per_hour, low=0)\n",
    "\n",
    "\n",
    "##### Color Bar\n",
    "color_bar = ColorBar(color_mapper = color_mapper,\n",
    "                     ticker = BasicTicker(),\n",
    "                    label_standoff=8,\n",
    "                     location=(0,0),\n",
    "                     orientation='vertical')\n",
    "\n",
    "p = figure(title=\"New York Taxi Pickups\",\n",
    "           plot_width=450, plot_height=750,\n",
    "           toolbar_location=None,\n",
    "           tools='pan,wheel_zoom,box_zoom,reset,save')\n",
    "p.xaxis.visible = False\n",
    "p.yaxis.visible = False\n",
    "\n",
    "p.xgrid.grid_line_color = None\n",
    "p.ygrid.grid_line_color = None\n",
    "\n",
    "#Get rid of zoom on axes:\n",
    "for t in p.tools:\n",
    "    if type(t) == WheelZoomTool:\n",
    "        t.zoom_on_axis = False\n",
    "\n",
    "patches = p.patches(xs=\"X\", ys=\"Y\", source=source,fill_alpha=1,\n",
    "                  fill_color={'field': 'Passengers',\n",
    "                              'transform': color_mapper},\n",
    "                  line_color=\"black\", alpha=0.5)\n",
    "\n",
    "hovertool = HoverTool(tooltips=[('Zone:', \"@ZoneName\"),\n",
    "                                (\"Passengers:\", \"@Passengers\")])\n",
    "p.add_tools(hovertool)\n",
    "\n",
    "p.add_layout(color_bar, 'right')\n",
    "\n",
    "st.bokeh_chart(p)\n",
    "\n",
    "'''\n",
    "**Ideas to improve**:\n",
    "\n",
    "- Day of week slider to buttons showing Monday, Tuesday, etc. instead of numbers.\n",
    "- Show day, hour and zone for máximum and minimum value.\n",
    "- Show line chart with pickup evolution throughout the day, and make it interactive, highlighting the zone selected in the map\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
