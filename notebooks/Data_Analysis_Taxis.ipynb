{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Premilinary Works\n",
    "How big is the file, number of rows, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/angelrps/git/MasterDataScience_FinalProject/data\n"
     ]
    }
   ],
   "source": [
    "cd ../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".:\r\n",
      "total 28491420\r\n",
      "-rwxrwxrwx 1 angelrps angelrps 10532305815 Mar 25 13:15 2017_Yellow_Taxi_Trip_Data.csv\r\n",
      "-rwxrwxrwx 1 angelrps angelrps 10428263736 Jun 18 12:58 2018_Yellow_Taxi_Trip_Data.csv\r\n",
      "-rwxrwxrwx 1 angelrps angelrps  8197837930 Apr  2 18:02 2019_Yellow_Taxi_Trip_Data.csv\r\n",
      "-rwxrwxrwx 1 angelrps angelrps      564780 Jun 18 11:15 Data_Weather_Cleaned.csv\r\n",
      "-rwxrwxrwx 1 angelrps angelrps      436485 Jun 16 10:51 LCD_documentation.pdf\r\n",
      "-rwxrwxrwx 1 angelrps angelrps    13843633 Jun 16 09:40 NOAA_CentralPark_Weather.csv\r\n",
      "-rwxrwxrwx 1 angelrps angelrps      196848 Apr  7 19:34 data_dictionary_trip_records_yellow.pdf\r\n",
      "-rwxrwxrwx 1 angelrps angelrps     1489310 Apr  7 19:34 taxi_zone_map_manhattan.jpg\r\n",
      "-rwxrwxrwx 1 angelrps angelrps      202694 Apr  4 12:46 trip_record_user_guide.pdf\r\n"
     ]
    }
   ],
   "source": [
    "!ls -Rl\n",
    "# 2017_Yellow_Taxi_Trip_Data.csv is 10532305815 bytes (9,80 GB)\n",
    "# 2018_Yellow_Taxi_Trip_Data.csv is 10428263736 bytes (9,71 GB)\n",
    "# 2019_Yellow_Taxi_Trip_Data.csv is 8197837930 bytes (7,63 GB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am dealing with very heavy files so I will compress them (bz2) to work with them\n",
    "# and remove the heavy .csv from my drive\n",
    "!bzip2 2017_Yellow_Taxi_Trip_Data.csv 2018_Yellow_Taxi_Trip_Data.csv 2019_Yellow_Taxi_Trip_Data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".:\r\n",
      "total 2897760\r\n",
      "-rwxrwxrwx 1 angelrps angelrps 1048588401 Mar 25 13:15 2017_Yellow_Taxi_Trip_Data.csv.bz2\r\n",
      "-rwxrwxrwx 1 angelrps angelrps 1065918551 Jun 18 12:58 2018_Yellow_Taxi_Trip_Data.csv.bz2\r\n",
      "-rwxrwxrwx 1 angelrps angelrps  835929368 Apr  2 18:02 2019_Yellow_Taxi_Trip_Data.csv.bz2\r\n",
      "-rwxrwxrwx 1 angelrps angelrps     564780 Jun 18 11:15 Data_Weather_Cleaned.csv\r\n",
      "-rwxrwxrwx 1 angelrps angelrps     436485 Jun 16 10:51 LCD_documentation.pdf\r\n",
      "-rwxrwxrwx 1 angelrps angelrps   13843633 Jun 16 09:40 NOAA_CentralPark_Weather.csv\r\n",
      "-rwxrwxrwx 1 angelrps angelrps     196848 Apr  7 19:34 data_dictionary_trip_records_yellow.pdf\r\n",
      "-rwxrwxrwx 1 angelrps angelrps    1489310 Apr  7 19:34 taxi_zone_map_manhattan.jpg\r\n",
      "-rwxrwxrwx 1 angelrps angelrps     202694 Apr  4 12:46 trip_record_user_guide.pdf\r\n"
     ]
    }
   ],
   "source": [
    "!ls -Rl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10748623\n",
      "10734230\n",
      "8402723\n"
     ]
    }
   ],
   "source": [
    "# Count Number of Lines\n",
    "!zgrep -c $ 2017_Yellow_Taxi_Trip_Data.csv.bz2\n",
    "!zgrep -c $ 2018_Yellow_Taxi_Trip_Data.csv.bz2\n",
    "!zgrep -c $ 2019_Yellow_Taxi_Trip_Data.csv.bz2\n",
    "\n",
    "# 2017_...10.748.623 lines\n",
    "# 2018_...10.734.230 lines\n",
    "# 2019_...8.402.723 lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I will start exploring the 2019 dataset\n",
    "I will try to use bash to clean the data as much as I can before importing a Data Frame because I believe is faster.\n",
    "From a previous exploration I concluded:\n",
    "1. There are trips with 0 'trip_distance'. I will remove all trips with 'trip_distance' < 0.06 (100 meters) because I consider them either measurement errors or non representative data.\n",
    "2. There are trips with either negative or very little 'fare_amount' (~0.01). I will remove rows with fare amount<1$ because I consider them measurement errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VendorID,tpep_pickup_datetime,tpep_dropoff_datetime,passenger_count,trip_distance,RatecodeID,store_and_fwd_flag,PULocationID,DOLocationID,payment_type,fare_amount,extra,mta_tax,tip_amount,tolls_amount,improvement_surcharge,total_amount,congestion_surcharge\r\n",
      "1,04/29/2019 11:31:03 AM,04/29/2019 11:31:03 AM,1,0,1,N,231,264,2,2.5,2.5,0.5,0,0,0.3,5.8,2.5\r\n",
      "2,04/29/2019 10:52:08 AM,04/29/2019 11:06:18 AM,1,1.01,1,N,186,230,1,10,0,0.5,2.66,0,0.3,15.96,2.5\r\n",
      "2,04/29/2019 11:28:40 AM,04/29/2019 11:33:01 AM,1,0.82,1,N,238,151,1,5,0,0.5,1.66,0,0.3,9.96,2.5\r\n",
      "1,04/29/2019 11:28:06 AM,04/29/2019 12:07:32 PM,1,12.1,1,N,138,88,1,38.5,2.5,0.5,10.4,0,0.3,52.2,2.5\r\n",
      "\r\n",
      "bzcat: I/O or other error, bailing out.  Possible reason follows.\r\n",
      "bzcat: Broken pipe\r\n",
      "\tInput file = ./2019_Yellow_Taxi_Trip_Data.csv.bz2, output file = (stdout)\r\n"
     ]
    }
   ],
   "source": [
    "!bzcat ./2019_Yellow_Taxi_Trip_Data.csv.bz2 | head -n 5\n",
    "\n",
    "# Conclusions:\n",
    "# 1. There is a header on the first line\n",
    "# 2. The separator is ','"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD LIBRARIES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9999, 18)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Prepare sample file with 10.000 rows\n",
    "#    Parse 'tpep_pickup_datetime' column to datetime object type\n",
    "dfsample = pd.read_csv('./2019_Yellow_Taxi_Trip_Data.csv.bz2', sep=',', nrows=9999,\n",
    "                      parse_dates={'pickup_datetime':['tpep_pickup_datetime']})\n",
    "dfsample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([], dtype='int64')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I WILL SUMMARIZE ALL STEPS IN EACH CELL\n",
    "\n",
    "# 1. Prepare sample file with 10.000 rows\n",
    "#    Parse 'tpep_pickup_datetime' column to datetime object type\n",
    "dfsample = pd.read_csv('./2019_Yellow_Taxi_Trip_Data.csv.bz2', sep=',', nrows=9999,\n",
    "                      parse_dates={'pickup_datetime':['tpep_pickup_datetime']})\n",
    "dfsample.shape\n",
    "\n",
    "# 2. Remove all trips with 'trip_distance' < 0.06 (100m) because I consider them measurement errors or non representative values\n",
    "DistIndex_to_drop = dfsample[dfsample['trip_distance'] < 0.06].index\n",
    "dfsample.drop(DistIndex_to_drop, inplace=True)\n",
    "dfsample[dfsample['trip_distance']<0.06].index # this should be none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [pickup_datetime, VendorID, tpep_dropoff_datetime, passenger_count, trip_distance, RatecodeID, store_and_fwd_flag, PULocationID, DOLocationID, payment_type, fare_amount, extra, mta_tax, tip_amount, tolls_amount, improvement_surcharge, total_amount, congestion_surcharge]\n",
       "Index: []"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I WILL SUMMARIZE ALL STEPS IN EACH CELL\n",
    "\n",
    "# 1. Prepare sample file with 10.000 rows\n",
    "#    Parse 'tpep_pickup_datetime' column to datetime object type\n",
    "dfsample = pd.read_csv('./2019_Yellow_Taxi_Trip_Data.csv.bz2', sep=',', nrows=9999,\n",
    "                      parse_dates={'pickup_datetime':['tpep_pickup_datetime']})\n",
    "dfsample.shape\n",
    "\n",
    "# 2. Remove all rows with 'trip_distance' < 0.06 (100m) because I consider them measurement errors or non representative values\n",
    "DistIndex_to_drop = dfsample[dfsample['trip_distance'] < 0.06].index\n",
    "dfsample.drop(DistIndex_to_drop, inplace=True)\n",
    "\n",
    "# 3. Remove rows with 'fare_amount' negative or <1$ because I consider them measurement errors or non relevant.\n",
    "FareIndex_to_drop = dfsample[dfsample['fare_amount']<0.01].index\n",
    "dfsample.drop(FareIndex_to_drop, inplace=True)\n",
    "dfsample[dfsample['fare_amount']<0.01] # this should be none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>PULocationID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-29 10:52:08</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2019-04-29 11:28:40</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2019-04-29 11:28:06</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2019-04-29 11:39:32</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2019-04-29 11:06:45</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pickup_datetime  PULocationID\n",
       "1 2019-04-29 10:52:08           186\n",
       "2 2019-04-29 11:28:40           238\n",
       "3 2019-04-29 11:28:06           138\n",
       "4 2019-04-29 11:39:32           138\n",
       "5 2019-04-29 11:06:45           141"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I WILL SUMMARIZE ALL STEPS IN EACH CELL\n",
    "\n",
    "# 1. Prepare sample file with 10.000 rows\n",
    "#    Parse 'tpep_pickup_datetime' column to datetime object type\n",
    "dfsample = pd.read_csv('./2019_Yellow_Taxi_Trip_Data.csv.bz2', sep=',', nrows=9999,\n",
    "                      parse_dates={'pickup_datetime':['tpep_pickup_datetime']})\n",
    "dfsample.shape\n",
    "\n",
    "# 2. Remove all rows with 'trip_distance' < 0.06 (100m) because I consider them measurement errors or non representative values\n",
    "DistIndex_to_drop = dfsample[dfsample['trip_distance'] < 0.06].index\n",
    "dfsample.drop(DistIndex_to_drop, inplace=True)\n",
    "\n",
    "# 3. Remove rows with 'fare_amount' negative or <1$ because I consider them measurement errors or non relevant.\n",
    "FareIndex_to_drop = dfsample[dfsample['fare_amount']<0.01].index\n",
    "dfsample.drop(FareIndex_to_drop, inplace=True)\n",
    "\n",
    "# 4. Select columns of interest.\n",
    "#    'pickup_datetime'\n",
    "#    'PULocationID'\n",
    "dfsample = dfsample[['pickup_datetime','PULocationID']]\n",
    "dfsample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# I WILL SUMMARIZE ALL STEPS IN EACH CELL\n",
    "\n",
    "# 1. Prepare sample file with 10.000 rows\n",
    "#    Parse 'tpep_pickup_datetime' column to datetime object type\n",
    "dfsample = pd.read_csv('./2019_Yellow_Taxi_Trip_Data.csv.bz2', sep=',', nrows=9999,\n",
    "                      parse_dates={'pickup_datetime':['tpep_pickup_datetime']})\n",
    "dfsample.shape\n",
    "\n",
    "# 2. Remove all rows with 'trip_distance' < 0.06 (100m) because I consider them measurement errors or non representative values\n",
    "DistIndex_to_drop = dfsample[dfsample['trip_distance'] < 0.06].index\n",
    "dfsample.drop(DistIndex_to_drop, inplace=True)\n",
    "\n",
    "# 3. Remove rows with 'fare_amount' negative or <1$ because I consider them measurement errors or non relevant.\n",
    "FareIndex_to_drop = dfsample[dfsample['fare_amount']<0.01].index\n",
    "dfsample.drop(FareIndex_to_drop, inplace=True)\n",
    "\n",
    "# 4. Select columns of interest.\n",
    "#    'pickup_datetime'\n",
    "#    'PULocationID'\n",
    "dfsample = dfsample[['pickup_datetime','PULocationID']]\n",
    "\n",
    "# 5. Set timestamp as index to visualize time series\n",
    "#dfsample.set_index('pickup_datetime', inplace=True)\n",
    "\n",
    "# 6. Convert the DATE in PERIODS of 1 hour\n",
    "#dfsample = dfsample.to_period(\"H\")\n",
    "#dfsample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PULocationID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2019-04-29 10:00</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  PULocationID\n",
       "2019-04-29 10:00           186"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_row = pd.DataFrame(dfsample.iloc[0]).T\n",
    "top_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PULocationID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2019-04-29 10:00</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-04-29 10:00</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-04-29 11:00</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-04-29 11:00</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-04-29 11:00</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 PULocationID\n",
       "pickup_datetime              \n",
       "2019-04-29 10:00          186\n",
       "2019-04-29 10:00          186\n",
       "2019-04-29 11:00          238\n",
       "2019-04-29 11:00          138\n",
       "2019-04-29 11:00          138"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DUPLICATING A ROW ON TOP TO TEST GROUPBY 'HOUR' AND 'NoOfPickups' SUM\n",
    "top_row = pd.DataFrame(dfsample.iloc[0]).T\n",
    "dfsample = pd.concat([top_row, dfsample]).reset_index(drop=True)\n",
    "dfsample.set_index('pickup_datetime', inplace=True)\n",
    "dfsample = dfsample.to_period(\"H\")\n",
    "dfsample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>NoOfPickups</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2019-04-29 10:00</td>\n",
       "      <td>186</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-04-29 10:00</td>\n",
       "      <td>186</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-04-29 11:00</td>\n",
       "      <td>238</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-04-29 11:00</td>\n",
       "      <td>138</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-04-29 11:00</td>\n",
       "      <td>138</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 PULocationID  NoOfPickups\n",
       "pickup_datetime                           \n",
       "2019-04-29 10:00          186            1\n",
       "2019-04-29 10:00          186            1\n",
       "2019-04-29 11:00          238            1\n",
       "2019-04-29 11:00          138            1\n",
       "2019-04-29 11:00          138            1"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I have to create a column 'n_of_pickups'.\n",
    "# Then groupby PULocationID and sum() by 'n_of_pickups'\n",
    "dfsample['NoOfPickups'] = 1\n",
    "dfsample.head()\n",
    "\n",
    "# Remember interpolate missing values every hour"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
