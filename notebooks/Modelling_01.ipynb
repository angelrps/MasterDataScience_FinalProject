{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this notebook I will explore different predictive models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".:\r\n",
      "total 145968\r\n",
      "-rw-rw-rw- 1 angelrps angelrps  550601 Jun 23 07:30 05-visualization_introduction_inclass.ipynb\r\n",
      "-rw-rw-rw- 1 angelrps angelrps  189652 Jun 19 09:19 Amadeus_Challenge_Class.ipynb\r\n",
      "-rwxrwxrwx 1 angelrps angelrps 7369019 Apr  7 19:34 Data_Analysis.ipynb\r\n",
      "-rw-rw-rw- 1 angelrps angelrps  752508 Jun 22 10:02 Data_Analysis_Taxis.ipynb\r\n",
      "-rwxrwxrwx 1 angelrps angelrps  371494 Jun 18 11:33 Data_Analysis_Weather.ipynb\r\n",
      "-rw-rw-rw- 1 angelrps angelrps 2387352 Jun 23 09:30 Data_Join_Taxis_Weather.ipynb\r\n",
      "-rwxrwxrwx 1 angelrps angelrps   10144 Apr  8 17:19 HowToTackleDataScienceChallenge.ipynb\r\n",
      "-rw-rw-rw- 1 angelrps angelrps    1429 Jun 23 13:06 Modelling_01.ipynb\r\n",
      "-rwxrwxrwx 1 angelrps angelrps 3527394 Jun 12 11:59 TSA.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls -Rl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/angelrps/git/MasterDataScience_FinalProject/data\n"
     ]
    }
   ],
   "source": [
    "cd ../data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import libraries and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1036854 entries, 0 to 1036853\n",
      "Data columns (total 13 columns):\n",
      "datetime               1036854 non-null datetime64[ns]\n",
      "PULocationID           1036854 non-null object\n",
      "NoOfPickups            1036854 non-null int64\n",
      "year                   1036854 non-null int64\n",
      "month                  1036854 non-null int64\n",
      "day                    1036854 non-null int64\n",
      "hour                   1036854 non-null int64\n",
      "week                   1036854 non-null int64\n",
      "dayofweek              1036854 non-null int64\n",
      "isweekend              1036854 non-null int64\n",
      "IsHoliday              1036854 non-null int64\n",
      "hourlyperiods          1036854 non-null int64\n",
      "HourlyPrecipitation    1036854 non-null float64\n",
      "dtypes: datetime64[ns](1), float64(1), int64(10), object(1)\n",
      "memory usage: 102.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# IMPORT LIBRARIES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. Import dataset\n",
    "\n",
    "df = pd.read_csv('../data/Data_Cleaned_2017_To_Model.csv', sep=',',\n",
    "                 dtype = {\"PULocationID\" : \"object\"},\n",
    "                 parse_dates=['datetime'])\n",
    "df.info() # check dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Separate variables\n",
    "INPUT variables: (must be Pandas DataFrame)\n",
    "    - month\n",
    "    - day\n",
    "    - hour\n",
    "    - is weekend\n",
    "    - PULocationID\n",
    "    - HourlyPrecipitation\n",
    "OUTPUT: (must Pandas Series)\n",
    "    - NoOfPickups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(pandas.core.frame.DataFrame, pandas.core.series.Series)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IMPORT LIBRARIES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. Import dataset\n",
    "\n",
    "df = pd.read_csv('../data/Data_Cleaned_2017_To_Model.csv', sep=',',\n",
    "                 dtype = {\"PULocationID\" : \"object\"},\n",
    "                 parse_dates=['datetime'])\n",
    "\n",
    "# 2. Separate variables\n",
    "X = df[['month','day','hour','PULocationID','HourlyPrecipitation']]\n",
    "y = df['NoOfPickups']\n",
    "type(X), type(y) # 'X' must be DataFrame and 'y' must be a Pandas Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Split data set\n",
    "\n",
    "I will use **train_test_split** from sklearn twice to split the data in:\n",
    "- Train: 60%\n",
    "- Validation: 20% (to validate training)\n",
    "- Test: 20% (to validate de model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Split data set\n",
    "# trainSize = 0.6\n",
    "valSize = 0.25 #0.8 * 0.2 = 0.2\n",
    "testSize = 0.2\n",
    "\n",
    "\n",
    "# Split TRAIN-TEST\n",
    "X_train, X_test, y_train, y_test \\\n",
    "    = train_test_split(X,y,test_size=testSize,random_state=1)\n",
    "\n",
    "# Split TRAIN-VALIDATION\n",
    "X_train, X_val, y_train, y_val \\\n",
    "    = train_test_split(X_train, y_train, test_size=valSize, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT LIBRARIES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. Import dataset\n",
    "\n",
    "df = pd.read_csv('../data/Data_Cleaned_2017_To_Model.csv', sep=',',\n",
    "                 dtype = {\"PULocationID\" : \"object\"},\n",
    "                 parse_dates=['datetime'])\n",
    "\n",
    "# 2. Separate variables\n",
    "X = df[['month','day','hour','PULocationID','HourlyPrecipitation']]\n",
    "y = df['NoOfPickups']\n",
    "type(X), type(y) # 'X' must be DataFrame and 'y' must be a Pandas Series\n",
    "\n",
    "# 2. Split data set\n",
    "# trainSize = 0.6\n",
    "valSize = 0.25 #0.8 * 0.2 = 0.2\n",
    "testSize = 0.2\n",
    "\n",
    "\n",
    "# 3.1 Split TRAIN-TEST\n",
    "X_train, X_test, y_train, y_test \\\n",
    "    = train_test_split(X,y,test_size=testSize,random_state=1)\n",
    "\n",
    "# 3.2 Split TRAIN-VALIDATION\n",
    "X_train, X_val, y_train, y_val \\\n",
    "    = train_test_split(X_train, y_train, test_size=valSize, random_state=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Models\n",
    "\n",
    "As the output variable is a number we need to solve a **regression** problem.\n",
    "\n",
    "I will start with the simplest regression model: **LINEAR REGRESSION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "date time object into unix-tipe format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1036854 entries, 0 to 1036853\n",
      "Data columns (total 13 columns):\n",
      "datetime               1036854 non-null datetime64[ns]\n",
      "PULocationID           1036854 non-null object\n",
      "NoOfPickups            1036854 non-null int64\n",
      "year                   1036854 non-null int64\n",
      "month                  1036854 non-null int64\n",
      "day                    1036854 non-null int64\n",
      "hour                   1036854 non-null int64\n",
      "week                   1036854 non-null int64\n",
      "dayofweek              1036854 non-null int64\n",
      "isweekend              1036854 non-null int64\n",
      "IsHoliday              1036854 non-null int64\n",
      "hourlyperiods          1036854 non-null int64\n",
      "HourlyPrecipitation    1036854 non-null float64\n",
      "dtypes: datetime64[ns](1), float64(1), int64(10), object(1)\n",
      "memory usage: 102.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# 4.1 Create an instance of the model\n",
    "reg = LinearRegression()\n",
    "\n",
    "# 4.2 Train the regressor\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# Do predictions\n",
    "#reg.predict([[2540],[3500],[4000]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
